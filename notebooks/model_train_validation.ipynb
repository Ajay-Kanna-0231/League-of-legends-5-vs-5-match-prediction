{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train_data_set.csv')\n",
    "print(train_df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.describe())\n",
    "# mean is around 0.437 that means there are almost equal no of 1 and 0's, so it's not imbalanced classes rather very balanced.\n",
    "# just judging based on accuracy shd be fine, no need of F1 score anol for balanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_corr = train_df.corr(method='pearson')['blue_win'].drop('blue_win')\n",
    "\n",
    "# Calculate Spearman correlation\n",
    "spearman_corr = train_df.corr(method='spearman')['blue_win'].drop('blue_win')\n",
    "\n",
    "# Combine the results into a DataFrame for easy comparison\n",
    "correlation_df = pd.DataFrame({\n",
    "    'Pearson': pearson_corr,\n",
    "    'Spearman': spearman_corr\n",
    "})\n",
    "\n",
    "# Sort by absolute values of Pearson correlation for better readability\n",
    "correlation_df = correlation_df.reindex(correlation_df['Pearson'].abs().sort_values(ascending=False).index)\n",
    "\n",
    "print(correlation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Plot Pearson correlations\n",
    "sns.barplot(x=correlation_df.index, y=correlation_df['Pearson'], color='blue', alpha=0.6, label='Pearson')\n",
    "\n",
    "# Plot Spearman correlations\n",
    "sns.barplot(x=correlation_df.index, y=correlation_df['Spearman'], color='red', alpha=0.6, label='Spearman')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Correlation with blue_win')\n",
    "plt.title('Pearson and Spearman Correlations with blue_win')\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(columns=['blue_win'])\n",
    "y = train_df['blue_win']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=10000),\n",
    "    'SVM': SVC(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'k-NN': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "model_scores = {}\n",
    "for model_name, model in models.items():\n",
    "    accuracy_scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
    "    f1_scores = cross_val_score(model, X, y, cv=skf, scoring='f1')\n",
    "    model_scores[model_name] = {\n",
    "        'accuracy_mean': np.mean(accuracy_scores),\n",
    "        'accuracy_std': np.std(accuracy_scores),\n",
    "    }\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "model_scores_df = pd.DataFrame(model_scores).T\n",
    "model_scores_df = model_scores_df[['accuracy_mean', 'accuracy_std']]\n",
    "\n",
    "# Sort by F1-score for better readability\n",
    "model_scores_df = model_scores_df.sort_values(by='accuracy_mean', ascending=False)\n",
    "\n",
    "print(model_scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = model_scores_df.index[0]\n",
    "best_model_accuracy = model_scores_df['accuracy_mean'][0]\n",
    "print(best_model_name, best_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(),\n",
    "        'param_grid': {\n",
    "            'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "            'C': [0.01, 0.1, 1, 10, 100],\n",
    "            'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "        }\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'param_grid': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'model': GradientBoostingClassifier(),\n",
    "        'param_grid': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'learning_rate': [0.01, 0.1, 1.0],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVC(),\n",
    "        'param_grid': {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "            'gamma': ['scale', 'auto'],\n",
    "            'degree': [3, 5]\n",
    "        }\n",
    "    },\n",
    "    'k-NN': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'param_grid': {\n",
    "            'n_neighbors': [3, 5, 7],\n",
    "            'weights': ['uniform', 'distance'],\n",
    "            'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "        }\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeClassifier(),\n",
    "        'param_grid': {\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'splitter': ['best', 'random'],\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "best_model = models[best_model_name]['model']\n",
    "param_grid = models[best_model_name]['param_grid']\n",
    "\n",
    "# Initialize GridSearchCV with the best model and its parameter grid\n",
    "grid_search = GridSearchCV(best_model, param_grid, cv=skf, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV to obtain the best parameters\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters for\", best_model_name, \":\", best_params)\n",
    "print(\"Best Accuracy:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_info = {\n",
    "    'model_name': best_model_name,\n",
    "    'best_params': best_params,\n",
    "    'best_accuracy': best_score\n",
    "}\n",
    "\n",
    "# Store best_model_info in a binary file using pickle\n",
    "with open('best_model_info.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model_info, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load best_model_info from the binary file\n",
    "with open('best_model_info.pkl', 'rb') as f:\n",
    "    best_model_info = pickle.load(f)\n",
    "\n",
    "# Now best_model_info contains your stored information\n",
    "print(best_model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv('chumma.csv')\n",
    "\n",
    "# Ensure the test DataFrame has the same structure as the training DataFrame\n",
    "X_test = test_df.drop(columns=['blue_win'])\n",
    "y_test = test_df['blue_win']\n",
    "\n",
    "# Assuming X_train was scaled with StandardScaler during training\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # This is for reference, during training\n",
    "\n",
    "# Scale the test data\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = best_model_info['model_name']\n",
    "best_params = best_model_info['best_params']\n",
    "\n",
    "# Initialize the model with the best parameters\n",
    "if best_model_name == 'Logistic Regression':\n",
    "    best_model = LogisticRegression(**best_params)\n",
    "elif best_model_name == 'Random Forest':\n",
    "    best_model = RandomForestClassifier(**best_params)\n",
    "elif best_model_name == 'SVM':\n",
    "    best_model = SVC(**best_params)\n",
    "elif best_model_name == 'Gradient Boosting':\n",
    "    best_model = GradientBoostingClassifier(**best_params)\n",
    "elif best_model_name == 'Decision Tree':\n",
    "    best_model = DecisionTreeClassifier(**best_params)\n",
    "elif best_model_name == 'k-NN':\n",
    "    best_model = KNeighborsClassifier(**best_params)\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported model: {best_model_name}\")\n",
    "\n",
    "# Fit the model on the entire training set (as the best parameters were found using cross-validation)\n",
    "best_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the test set results\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
